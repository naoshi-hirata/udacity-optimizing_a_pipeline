# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources
- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)


## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
This dataset contains data about customers and whether or not they have subscribed to a term deposit. We seek to predict whether or not they will subscribe to a term deposit.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
The best performing model was a VotingEnsemble.
 
## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
Scikit-learn pipeline create a model using the Logistic Regression algorithm to predict whether a customer will subscribe to a term deposit using the bankmarketing_train.csv dataset. Generate models with random combinations of hyperparameters C (0.1, 1, 10) and max_iter (50, 100, 150) and compare their accuracies.
<img width="861" alt="scikit-learn_pipeline_architecture" src="https://user-images.githubusercontent.com/105419001/225234925-6cb4d960-87ef-49f2-9ee6-924ead276d50.PNG">


**What are the benefits of the parameter sampler you chose?**
The benefits of hyperparameters sampler:
1. Random sampling: The use of a random sampler ensures that a wide range of hyperparameter combinations are tried, which can increase the chances of finding the optimal set of hyperparameters.

2. Diverse options: The sampler includes a diverse range of options for the hyperparameters, providing flexibility and allowing for a broad exploration of the hyperparameter space.

3. Time and resource efficiency: The sampler can help to optimize the use of time and resources by enabling the user to test a variety of hyperparameter combinations in a more efficient manner.

4. Generalization: By testing multiple hyperparameter combinations, the sampler can help to create a model that is more likely to generalize well to new, unseen data. 

**What are the benefits of the early stopping policy you chose?**
The benefits of BanditPolicy(evaluation_interval=2, slack_factor=0.1):

1. Resource efficiency: The policy can help to optimize the use of resources by allowing the user to terminate poorly performing runs early, reducing the number of unnecessary iterations.

2. Time efficiency: By terminating poorly performing runs early, the policy can help to reduce the overall time needed to find the best hyperparameters.

3. Improved results: The policy can help to improve the final results by allowing the user to allocate more resources to better-performing runs.

4. Adaptive: The slack_factor parameter in the policy allows for adaptation to the changing optimization landscape, making it more robust and effective in finding the best hyperparameters.

5. Automated: The BanditPolicy is an automated method for hyperparameter tuning that does not require user intervention, allowing for a more streamlined and efficient tuning process.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
The algorizm which perform best is VotingEnsemble. I didn't check hyperparameters.

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
The accuracy of VotingEnsemble in autoML is higher than LogisticRegression a little. VotingEnsemble use several algorizms and predict by voting. The doffernce caused by algorizm, hyperparameters, and training data.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
Equalizing the number of data points for each class across features. A model is considered incorrect if it has high correlation with the data but no relationship with the target variable (y-value).

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
![image](https://user-images.githubusercontent.com/105419001/225190575-f7a4e3f9-e177-4486-801b-67d1b2ed59d9.png)


